---
name: mock-exam-evaluator
description: Evaluates a completed mock exam with comprehensive section breakdown, fatigue detection, time management analysis, and real exam score prediction with confidence intervals. Use after student completes a mock exam generated by mock-exam-generator.
phase: 4
category: MASTERY
priority: P0
---

# Mock Exam Evaluator

Provides comprehensive evaluation of mock exam results including section breakdown, performance analysis, and predictive scoring.

## MCP Integration

This skill uses the **filesystem MCP server** for reading exam data and writing results.

### Required MCP Tools
- `mcp__filesystem__read_file` - Read mock exam session and question bank
- `mcp__filesystem__write_file` - Save evaluation results

## Section Breakdown Logic

### Section Evaluation
For each of the 5 sections:
```
section_score = {
  "name": section_name,
  "correct": count_correct,
  "total": 20,
  "accuracy": (correct / 20) * 100,
  "time_avg_seconds": avg_time_per_question,
  "difficulty_breakdown": {
    "easy": {correct: x, total: 6},
    "medium": {correct: y, total: 10},
    "hard": {correct: z, total: 4}
  }
}
```

### Section Names and Question Ranges
| Section | Questions | Subject |
|---------|-----------|---------|
| 1 | 1-20 | pakistan_studies |
| 2 | 21-40 | general_knowledge |
| 3 | 41-60 | current_affairs |
| 4 | 61-80 | english |
| 5 | 81-100 | math_reasoning |

## Fatigue Detection Algorithm

Detects accuracy decline as exam progresses:

```
1. Calculate accuracy for each 10-question block:
   blocks = [Q1-10, Q11-20, Q21-30, ..., Q91-100]
   block_accuracies = [accuracy for each block]

2. Detect fatigue pattern:
   For i in range(len(blocks) - 2):
     if blocks[i+1] < blocks[i] AND blocks[i+2] < blocks[i+1]:
       fatigue_detected_at = (i + 1) * 10 + 1
       break

3. Calculate accuracy trend:
   first_half = avg(blocks[0:5])
   second_half = avg(blocks[5:10])

   if second_half < first_half - 10:
     accuracy_trend = "declining_after_q50"
   elif second_half < first_half - 5:
     accuracy_trend = "slight_decline"
   else:
     accuracy_trend = "stable"
```

## Real Exam Score Prediction

### Prediction Model
```
1. Base prediction from mock score:
   base_score = overall_accuracy

2. Apply historical adjustment:
   If student has previous mocks:
     mock_avg = average(previous_mock_scores)
     trend = current_score - mock_avg
     adjusted_score = base_score + (trend * 0.3)

3. Apply exam day factor:
   - Typical decline under real pressure: -5 to -10 points
   exam_factor = -7  # Conservative estimate

4. Calculate prediction:
   predicted_score = adjusted_score + exam_factor

5. Calculate confidence interval:
   Based on score variance and sample size:
   std_dev = calculate_std_dev(all_mock_scores)
   margin = 1.96 * std_dev / sqrt(mock_count)

   confidence_interval = [
     predicted_score - margin,
     predicted_score + margin
   ]
```

### Readiness Determination
```
If predicted_score >= 70 AND confidence_lower >= 60:
  ready_for_exam = true
  recommended_mock_count = 0
Elif predicted_score >= 60:
  ready_for_exam = false
  recommended_mock_count = 2
Else:
  ready_for_exam = false
  recommended_mock_count = 5
```

## Execution Steps

1. **Load mock exam session and answers**
   ```
   session = read_file(mock-exams/{session_id}.json)
   answers = read_file(answer key from question bank)
   ```

2. **Evaluate each answer**
   ```
   For each question:
     is_correct = student_answer == correct_answer
     time_spent = answer_timestamp - question_start
   ```

3. **Calculate section breakdown**
   ```
   For each section in [pakistan_studies, general_knowledge, current_affairs, english, math_reasoning]:
     section_questions = questions[section_range]
     section_score = calculate_section_score(section_questions)
   ```

4. **Detect fatigue pattern**
   ```
   block_accuracies = calculate_block_accuracies()
   fatigue_detected_at = detect_fatigue_point(block_accuracies)
   accuracy_trend = determine_trend(block_accuracies)
   ```

5. **Analyze time management**
   ```
   avg_time = total_time / completed_questions
   rushed_sections = sections where avg_time < 60 seconds
   slow_sections = sections where avg_time > 150 seconds

   time_management = determine_time_assessment(rushed_sections, slow_sections)
   ```

6. **Calculate predictions**
   ```
   predicted_score = calculate_prediction(overall_score, historical_mocks)
   confidence_interval = calculate_confidence(mock_history)
   ready_for_exam = determine_readiness(predicted_score, confidence_interval)
   ```

7. **Build comprehensive results**

8. **Save evaluation results**

## Input Schema

```json
{
  "session_id": {
    "type": "string",
    "required": true,
    "description": "Mock exam session ID to evaluate"
  },
  "student_id": {
    "type": "string",
    "required": true
  },
  "student_answers": {
    "type": "array",
    "required": true,
    "items": {
      "question_number": "integer 1-100",
      "selected_answer": "A | B | C | D | null",
      "answered_at": "ISO 8601 timestamp"
    }
  },
  "exam_started_at": {
    "type": "string",
    "format": "ISO 8601",
    "required": true
  },
  "exam_ended_at": {
    "type": "string",
    "format": "ISO 8601",
    "required": true
  }
}
```

## Output Schema

```json
{
  "session_id": "string",
  "student_id": "string",
  "exam_type": "SPSC | PPSC | KPPSC",
  "results": {
    "completed_questions": "integer",
    "time_taken_minutes": "integer",
    "time_per_question_avg_seconds": "number",
    "section_breakdown": {
      "<section_name>": {
        "correct": "integer",
        "total": "integer (always 20)",
        "accuracy": "number 0-100",
        "time_avg_seconds": "number"
      }
    },
    "overall_score": "number 0-100",
    "percentile_estimate": "number 0-100 (optional)"
  },
  "analysis": {
    "pressure_handling": "low | moderate | high",
    "fatigue_detected_at_question": "integer | null",
    "accuracy_trend": "string",
    "time_management": "string"
  },
  "predictions": {
    "predicted_real_exam_score": "number 0-100",
    "confidence_interval": ["number", "number"],
    "ready_for_exam": "boolean",
    "recommended_mock_count": "integer"
  },
  "created_at": "ISO 8601"
}
```

## File Paths

| Operation | Path |
|-----------|------|
| Read | `memory/students/{student_id}/mock-exams/{session_id}.json` |
| Read | `question-bank/{exam_type}/{subject}/*.json` (for correct answers) |
| Write | `memory/students/{student_id}/mock-exams/{session_id}.json` (update with results) |

## Pressure Handling Assessment

Based on accuracy in first 20 questions vs overall:
```
first_20_accuracy = accuracy(questions[1:20])
overall_accuracy = accuracy(all_questions)

if first_20_accuracy - overall_accuracy > 15:
  pressure_handling = "low"  # Started well, declined significantly
elif first_20_accuracy - overall_accuracy > 5:
  pressure_handling = "moderate"
else:
  pressure_handling = "high"  # Maintained consistency
```

## Time Management Assessment

```
if completed_questions < 95:
  time_management = "incomplete_exam"
elif any(section.time_avg < 60):
  time_management = "rushed_sections"
elif any(section.time_avg > 150):
  time_management = "slow_sections"
else:
  time_management = "well_paced"
```

## Constraints

- Must evaluate all 100 questions
- Must produce section breakdown for all 5 sections
- Must detect fatigue if present
- Confidence interval must be provided
- Must handle incomplete exams (unanswered questions)
- Must calculate predictions based on available data
- Results must be saved to mock exam session file

## Example Output

```json
{
  "session_id": "mock-2025-02-02-001",
  "student_id": "student_123",
  "exam_type": "PPSC",
  "results": {
    "completed_questions": 95,
    "time_taken_minutes": 165,
    "time_per_question_avg_seconds": 104,
    "section_breakdown": {
      "pakistan_studies": {"correct": 18, "total": 20, "accuracy": 90, "time_avg_seconds": 95},
      "general_knowledge": {"correct": 15, "total": 20, "accuracy": 75, "time_avg_seconds": 120},
      "current_affairs": {"correct": 17, "total": 20, "accuracy": 85, "time_avg_seconds": 85},
      "english": {"correct": 14, "total": 20, "accuracy": 70, "time_avg_seconds": 110},
      "math_reasoning": {"correct": 12, "total": 20, "accuracy": 60, "time_avg_seconds": 130}
    },
    "overall_score": 76,
    "percentile_estimate": 72
  },
  "analysis": {
    "pressure_handling": "moderate",
    "fatigue_detected_at_question": 85,
    "accuracy_trend": "declining_after_q70",
    "time_management": "rushed_final_section"
  },
  "predictions": {
    "predicted_real_exam_score": 72,
    "confidence_interval": [68, 76],
    "ready_for_exam": false,
    "recommended_mock_count": 3
  },
  "created_at": "2025-02-02T14:30:00Z"
}
```

## Usage Notes

- Use after mock-exam-generator creates the exam
- Requires student_answers from completed exam
- Updates the original mock exam session file with results
- Use predictions to guide study plan adjustments
- Track fatigue patterns across multiple mocks
